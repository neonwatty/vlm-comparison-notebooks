{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1867969f-9417-41e2-bdc6-bdff6c142674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (780.4 MB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.5.1+cu121 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.5.1+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.5.1+cu121\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# install moondream dependencies\n",
    "!pip install --upgrade torch --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241ef8b2-6a55-42e7-ac78-65fb4d31b3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash_attn\n",
      "  Using cached flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash_attn) (2.5.1+cu121)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash_attn) (0.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2025.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash_attn) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->flash_attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash_attn) (2.1.2)\n",
      "Building wheels for collected packages: flash_attn\n",
      "  Building wheel for flash_attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash_attn: filename=flash_attn-2.7.4.post1-cp310-cp310-linux_x86_64.whl size=187797312 sha256=b267f80a08e516292cdd748056a2178a45b8abedf7fca123292eb17c21c8c87c\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/ce/d5/08ea07bfc16ba218dc65a3a7ef9b6a270530bcbd2cea2ee1ca\n",
      "Successfully built flash_attn\n",
      "Installing collected packages: flash_attn\n",
      "Successfully installed flash_attn-2.7.4.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install flash_attn # requires torch > 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b600cc34-2e03-47bb-8b8c-191ce28b8284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n",
      "INFO: starting download or loading of model - smolVLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: ... done\n",
      "INFO: starting image to text extraction for image ./examples/both pills.jpeg...\n",
      "INFO: ... done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The image features a close-up of a man\\'s face. He appears to be in a somewhat serious or contemplative mood, as indicated by his expression and the way his eyes are directed downwards. The man\\'s expression is intense and focused, with a slight furrowed brow and a furrowed chin. His hair is short and appears to be bald, and he is wearing dark sunglasses that cover his eyes. The background of the image is blurred, which helps to focus the viewer\\'s attention on the man\\'s face.\\n\\nThe text on the image is superimposed on the image. The text is in white and is positioned at the top and bottom of the image. The text reads:\\n\\n\"Did you just take both pills?\"\\n\\nThe font of the text is bold and sans-serif, making it easy to read. The phrase \"Did you just take both pills?\" is in a conversational tone, suggesting that the man might be asking a question related to his health or medication.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "\"\"\"\n",
    "smolvlm-256m is a 0.25B text-to-image model that has several interesting capabilities trained in.\n",
    "These include:\n",
    "- captioning - with various lengths\n",
    "- general querying (e.g., \"how many people are in this image?\")\n",
    "- translate text on image\n",
    "\n",
    "There are several smaller versions of the model as well.\n",
    "\n",
    "the repo: https://huggingface.co/collections/HuggingFaceTB/smolvlm-256m-and-500m-6791fafc5bb0ab8acc960fb0\n",
    "\"\"\"\n",
    "\n",
    "# Automatically determine the best available device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"  # Metal (Apple Silicon)\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"  # NVIDIA GPU\n",
    "else:\n",
    "    device = \"cpu\"  # Fallback to CPU\n",
    "\n",
    "print('device is', device)\n",
    "\n",
    "def smolvlm_image_to_text(image_path: str) -> str:\n",
    "    # instantiate the model\n",
    "    print(\"INFO: starting download or loading of model - smolVLM...\")\n",
    "    \n",
    "    # Initialize processor and model\n",
    "    model_size = \"HuggingFaceTB/SmolVLM-256M-Instruct\" # HuggingFaceTB/SmolVLM-500M-Instruct\n",
    "    processor = AutoProcessor.from_pretrained(model_size)\n",
    "    model = AutoModelForVision2Seq.from_pretrained(\n",
    "        model_size,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        _attn_implementation=\"eager\" #\"flash_attention_2\" if device == \"cuda\" else \"eager\",\n",
    "    ).to(device)\n",
    "    print(\"INFO: ... done\")\n",
    "\n",
    "    print(f\"INFO: starting image to text extraction for image {image_path}...\")\n",
    "    image = Image.open(image_path)\n",
    "    # Create input messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "                {\"type\": \"text\", \"text\": \"Can you describe this image?\"}\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # Prepare inputs\n",
    "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    # Generate outputs\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=250)\n",
    "    generated_texts = processor.batch_decode(\n",
    "        generated_ids,\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "    print(\"INFO: ... done\")\n",
    "\n",
    "    # clean up\n",
    "    raw_output = generated_texts[0]\n",
    "\n",
    "    substring = \"Can you describe this image?\"\n",
    "    if substring in raw_output:\n",
    "        raw_output = raw_output.split(substring, 1)[-1].strip()\n",
    "    substring = \"### Analysis and Description:\"\n",
    "    if substring in raw_output:\n",
    "        raw_output = raw_output.split(substring, 1)[0].strip()\n",
    "    substring = \"Assistant: \"\n",
    "    if substring in raw_output:\n",
    "        raw_output = raw_output.split(substring, 1)[-1].strip()\n",
    "    return raw_output\n",
    "    \n",
    "image_path = \"./examples/both pills.jpeg\"\n",
    "smolvlm_image_to_text(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ab023-7adb-41b0-9530-71447c4e292c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
